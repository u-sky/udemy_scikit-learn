{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=1, \n",
    "                  train_size=0.8,\n",
    "                  test_size=0.2, \n",
    "                  random_state=0)\n",
    "\n",
    "train_index, test_index = next(ss.split(X, y))\n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmat = confusion_matrix(y_test, y_pred)\n",
    "cmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.decision_function(X_test[12:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict(X_test[12:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(clf.decision_function(X_test[12:15]) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(clf.decision_function(X_test[12:15]) > 0.5).astype(int) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(clf.decision_function(X_test[12:15]) > -2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(clf.decision_function(X_test[12:15]) > 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for th in range(-3,7):\n",
    "    print(th, (clf.decision_function(X_test[12:15]) > th).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = clf.decision_function(X_test)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, test_score)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "print(\"AUC = \", auc(fpr, tpr))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.ylabel('True Positive Rate (recall)')\n",
    "plt.xlabel('False Positive Rate (1-specificity)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = clf.decision_function(X_test)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, test_score)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = clf.decision_function(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, test_score)\n",
    "plt.plot(fpr, tpr, label=\"result\")\n",
    "print(\"result AUC = \", auc(fpr, tpr))\n",
    "\n",
    "test_score = np.random.uniform(size=y_test.size)# もしまったくランダムなら\n",
    "fpr, tpr, _ = roc_curve(y_test, test_score)\n",
    "plt.plot(fpr, tpr, label=\"random / chance\")\n",
    "print(\"chance AUC = \", auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test) # 完璧なら\n",
    "plt.plot(fpr, tpr, label=\"perfect\")\n",
    "print(\"perfect AUC = \", auc(fpr, tpr))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.ylabel('True Positive Rate (recall)')\n",
    "plt.xlabel('False Positive Rate (1-specificity)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = clf.decision_function(X_test)\n",
    "precision, recall, _ = precision_recall_curve(y_test, test_score)\n",
    "plt.plot(recall, precision, label=\"result\")\n",
    "\n",
    "test_score = np.random.uniform(size=y_test.size) # もしまったくランダムなら\n",
    "precision, recall, _ = precision_recall_curve(y_test, test_score)\n",
    "plt.plot(recall, precision, label=\"random\")\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_test) # 完璧なら\n",
    "plt.plot(recall, precision, label=\"perfect\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf for average precision and interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_score = np.random.uniform(size=y_test.size) # もしまったくランダムなら\n",
    "precision, recall, _ = precision_recall_curve(y_test, test_score)\n",
    "\n",
    "precision_interp = np.maximum.accumulate(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(recall, precision, marker=\".\", label=\"precision\")\n",
    "plt.plot(recall, precision_interp, marker=\".\", label=\"interpolated precision\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_precision = np.interp(np.arange(0, 1.1, 0.1),\n",
    "                          recall[::-1], \n",
    "                          precision_interp[::-1])\n",
    "AP = all_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(all_precision)\n",
    "print(AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_AP(precision, recall):\n",
    "    precision_interp = np.maximum.accumulate(precision)\n",
    "    all_precision = np.interp(np.arange(0, 1.1, 0.1), recall[::-1], precision_interp[::-1])\n",
    "    AP = all_precision.mean()\n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = clf.decision_function(X_test)\n",
    "precision, recall, _ = precision_recall_curve(y_test, test_score)\n",
    "calc_AP(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=1, \n",
    "                  train_size=0.8, \n",
    "                  test_size=0.2, \n",
    "                  random_state=0)\n",
    "\n",
    "train_index, test_index = next(ss.split(X, y))\n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fpr, tpr, _ = roc_curve((y_test == i).astype(int), \n",
    "                            test_score[:,i])\n",
    "    plt.plot(fpr, tpr, label=\"{0}, {1:.2f}\".format(i, auc(fpr, tpr)))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc=\"best\", title=\"class, AUC\")\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.ylabel('True Positive Rate (recall)')\n",
    "plt.xlabel('False Positive Rate (1-specificity)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fpr, tpr, _ = roc_curve((y_test == i).astype(int), \n",
    "                            test_score[:,i])\n",
    "    plt.plot(fpr, tpr, label=\"{0}, {1:.2f}\".format(i, auc(fpr, tpr)))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend(loc=\"best\", title=\"class, AUC\")\n",
    "plt.xlim([-0.01, 0.2])\n",
    "plt.ylim([0.8, 1.01])\n",
    "plt.ylabel('True Positive Rate (recall)')\n",
    "plt.xlabel('False Positive Rate (1-specificity)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    precision, recall, _ = precision_recall_curve((y_test == i).astype(int), \n",
    "                            test_score[:,i])\n",
    "    plt.plot(recall, precision, label=\"{0}\".format(i))\n",
    "             \n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mAP of PASCAL VOC by http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf\n",
    "\n",
    "APs = []\n",
    "for i in range(10):\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve((y_test == i).astype(int), test_score[:,i])\n",
    "    APs.append( calc_AP(precision, recall) )\n",
    "    \n",
    "APs = np.array(APs)\n",
    "mAP = APs.mean()\n",
    "\n",
    "print(APs)\n",
    "print(\"mAP = \", mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
